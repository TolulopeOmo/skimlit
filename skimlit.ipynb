{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "skimlit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnYie73lr07q"
      },
      "source": [
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts.\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
        "\n",
        "In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
        "\n",
        "Problem in a sentence\n",
        "\n",
        "The number of RCT papers published is growing, and those without organized abstracts can be difficult to read, slowing researchers' progress through the literature.\n",
        "\n",
        "Solution in a sentence\n",
        "\n",
        "Create an NLP model that categorizes abstract statements according to their function (e.g., objective, methods, outcomes, etc.) to allow scholars to skim through the literature (thus SkimLit) and delve deeper when needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsuQCg5Uaw1w",
        "outputId": "328933ab-25d7-4076-b738-05a7fb2b9144"
      },
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P4 (UUID: GPU-9d3a83dd-b5c1-0bc1-baa0-d6c9862e4c17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MdzfDdzaQCb"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0qt0M55a98x",
        "outputId": "ce028d54-0c0b-423c-daf7-63baced1bc08"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crmxKEJ69bNW",
        "outputId": "e0a21fce-e709-496f-8e05-7abc2f9a460b"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Zp21fGbBUJ"
      },
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWqMrjLCbFTr",
        "outputId": "5ec0cc11-ab46-4f24-d652-490c15459d1a"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yjdhJxbbIhX"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text file) and returns the lines of text as a list.\n",
        "  \n",
        "  Args:\n",
        "      filename: a string containing the target filepath to read.\n",
        "  \n",
        "  Returns:\n",
        "      A list of strings with one string per line from the target filename.\n",
        "      For example:\n",
        "      [\"this is the first line of filename\",\n",
        "       \"this is the second line of filename\",\n",
        "       \"...\"]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT7RMQsEbI0I",
        "outputId": "d0de9f94-cb20-4c60-8d90-8597b05099d2"
      },
      "source": [
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:20] # the whole first example of an abstract + a little more of the next one"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-IfwKVAbJAy"
      },
      "source": [
        "Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n",
        "\n",
        "The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n",
        "\n",
        "Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n",
        "\n",
        "Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine learning model.\n",
        "\n",
        "Writing a function to perform the following steps:\n",
        "* Take a target file of abstract samples.\n",
        "* Read the lines in the target file.\n",
        "* For each line in the target file:  \n",
        "  * If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n",
        "    * Keep count of the number of lines in a sample.\n",
        "  * If the line begins with `\\n` mark it as the end of an abstract sample.\n",
        "    * Keep count of the total lines in a sample.\n",
        "  * Record the text before the `\\t` as the label of the line.\n",
        "  * Record the text after the `\\t` as the text of the line.\n",
        "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n",
        "  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n",
        "  * `\"text\"` - the text of the line in the abstract.\n",
        "  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n",
        "* Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65Ffn9abJKH"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "  \n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDd28-PfgoUP",
        "outputId": "9c2a748e-b2b2-4908-800b-8c0b76010ae7"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 511 ms, sys: 105 ms, total: 616 ms\n",
            "Wall time: 616 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcYkHrnnh0lf",
        "outputId": "2fc691a3-dae6-45d8-b527-03bac5b13efb"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "RRSTUXuth9jJ",
        "outputId": "4b736fbd-5416-45f3-f80f-fa404014ab91"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnQIDiJPg231",
        "outputId": "fcb420a5-00f1-4215-b897-2dd333142cd5"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoZbOMqUhL2l"
      },
      "source": [
        "Looks like sentences with the `OBJECTIVE` label are the least common.\n",
        "\n",
        "How about we check the distribution of our abstract lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "tkCRIBWbhUmD",
        "outputId": "70be8d82-57ad-43b3-e880-a94911b4d430"
      },
      "source": [
        "\n",
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2kPnlNhy0L"
      },
      "source": [
        "Most of the abstracts are around 7 to 15 sentences in length.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqps0Jw0wcQo"
      },
      "source": [
        "### Get lists of sentences\n",
        "\n",
        "When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybvBrdPKwmDR",
        "outputId": "ed2c5aab-b1d6-4c5d-9a00-ad1cd69cc88b"
      },
      "source": [
        "# Convert abstract text lines into lists \n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-OPWZPei46_",
        "outputId": "013c414a-73b0-42f4-d6ac-bbcc6e7368bd"
      },
      "source": [
        "# View first 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk1tXXANaxhK"
      },
      "source": [
        "## Make numeric labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riWJb105awwn",
        "outputId": "de52f65a-33d3-42da-8503-5d8fb43c711a"
      },
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG-iZttkkCjL"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG8LmKhAozc_",
        "outputId": "76a0cc6c-076d-4659-e98b-4517c730331d"
      },
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd-uax-AkExg"
      },
      "source": [
        "Now we've trained an instance of `LabelEncoder`, we can get the class names and number of classes using the `classes_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeQ1OQ9glVaz",
        "outputId": "7d644409-1caf-42ad-d7db-94437837e9d8"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJD7X7atahFC"
      },
      "source": [
        "## Model 0: Getting a baseline \n",
        "\n",
        "Our first model we'll be a TF-IDF Multinomial Naive Bayes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km5hWlVymnxv"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences, \n",
        "            y=train_labels_encoded);"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGUtAzKem-dO"
      },
      "source": [
        "Due to the speed of the Multinomial Naive Bayes algorithm, it trains very quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq7BAPCmn1bM",
        "outputId": "e7469bae-6324-4e31-b5a3-2ad7d78128ae"
      },
      "source": [
        "# Evaluate baseline on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp0aq6XpnPCG"
      },
      "source": [
        "Looks like 72.1% accuracy will be the number to beat with our deeper models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuGl9z2NjAl8",
        "outputId": "2189090e-4a44-4a48-a70c-0e652b0b9299"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5GaqHjtHWUM"
      },
      "source": [
        "Download helper functions script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6y-nK2tGwOL",
        "outputId": "9d08249c-97c0-4513-d370-96f8112011b8"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 12:13:34--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: helper_functions.py.1\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-20 12:13:34 (78.9 MB/s) - helper_functions.py.1 saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmXBYc5SHitH"
      },
      "source": [
        "Now we've got the helper functions script we can import the `caculate_results()` function and see how our baseline model went."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P44NMOt1GzZL"
      },
      "source": [
        "# Import calculate_results helper function\n",
        "from helper_functions import calculate_results"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WN_TLx2jv7T",
        "outputId": "fb176de0-2109-426a-dfb5-960fe88ce0c6"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MADIlN1QaiTW"
      },
      "source": [
        "Preparing our data for deep sequence models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCR0F7Rhptcp"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTEPCjOuUNdj"
      },
      "source": [
        "Since we'll be turning our sentences into numbers, it's a good idea to figure out how many words are in each sentence.\n",
        "\n",
        "When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n",
        "\n",
        "For example, if one sentence is eight words long and another is 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y-V_9-KrH7y",
        "outputId": "5f0aea40-c245-462b-e7af-44d890f26c5b"
      },
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len # return average sentence length (in tokens)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oToFcpVTU6fU"
      },
      "source": [
        "How about the distribution of sentence lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Y9S27ACkroai",
        "outputId": "ca9b3b4f-e4ee-482e-d340-3875a25263ab"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=7);"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_Yaz1U9yJ"
      },
      "source": [
        "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e5nUagxr4r5",
        "outputId": "39213154-db9c-4e2d-f7a6-e14d9523f36f"
      },
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhre7MPBVfK2"
      },
      "source": [
        "It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEZbyvh1WCBw",
        "outputId": "988a19d7-24e0-4d58-d0a6-dedc99c1f71b"
      },
      "source": [
        "# Maximum sentence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWIlFV4WF8R"
      },
      "source": [
        "However, since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (sinces all sentences below the max length would get padded with zeros).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvhbRw7-uMwH"
      },
      "source": [
        "Create text vectorizer\n",
        "\n",
        "PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our max_tokens parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xniPYW60uzby"
      },
      "source": [
        "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu25jIo-YSuW"
      },
      "source": [
        "And since discovered a sentence length of 55 covers 95% of the training sentences, we'll use that as our `output_sequence_length` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtfQ27MNpy-v"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
        "                                    output_sequence_length=55) # desired output length of vectorized sequences"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJtmyd1sWW8"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVZDwaymsbLa",
        "outputId": "5fb36f79-062c-42d8-bd1f-c41c343610ee"
      },
      "source": [
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\n",
            "at baseline , @ % were living with hiv , and @ % tested positive for viral hepatitis or at least one sti ( other than hiv ) .\n",
            "\n",
            "Length of text: 29\n",
            "\n",
            "Vectorized text:\n",
            "[[  15   49    9 1147    7  500    3  567  280   11 1504 1363   16   15\n",
            "   322   88 6340  168   42  500    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS80FGEhsgVe",
        "outputId": "7d2bef93-9158-43c0-e863-e5e4e5d0cc66"
      },
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly5BSLkGZnPO",
        "outputId": "aad3bba7-c045-44b0-e04d-8467a3a5bfd6"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZvDSTrTp1Wy"
      },
      "source": [
        "Create custom text embedding\n",
        "Our token_vectorization layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
        "\n",
        "To create a richer numerical representation of our text, we can use an embedding.\n",
        "\n",
        "As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
        "\n",
        "\n",
        "The input_dim parameter defines the size of our vocabulary. And the output_dim parameter defines the dimension of the embedding output.\n",
        "\n",
        "Once created, our embedding layer will take the integer outputs of our text_vectorization layer as inputs and convert them to feature vectors of size output_dim.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIKPM2QOuLQv",
        "outputId": "1c436459-bd65-4544-84d5-ab03f06a9ebe"
      },
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               # Use masking to handle variable sequence lengths (save space)\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\") \n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "at baseline , @ % were living with hiv , and @ % tested positive for viral hepatitis or at least one sti ( other than hiv ) .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[  15   49    9 1147    7  500    3  567  280   11 1504 1363   16   15\n",
            "   322   88 6340  168   42  500    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.02191922 -0.02726517  0.04529855 ...  0.02660147 -0.01122342\n",
            "   -0.01572812]\n",
            "  [-0.02514254  0.04473908  0.04346556 ...  0.02766793  0.0074973\n",
            "   -0.00749612]\n",
            "  [-0.01314448  0.01893388 -0.03127751 ...  0.00116056 -0.03858533\n",
            "    0.02653027]\n",
            "  ...\n",
            "  [ 0.013818   -0.02871808  0.01791539 ... -0.044367    0.02170904\n",
            "    0.01009528]\n",
            "  [ 0.013818   -0.02871808  0.01791539 ... -0.044367    0.02170904\n",
            "    0.01009528]\n",
            "  [ 0.013818   -0.02871808  0.01791539 ... -0.044367    0.02170904\n",
            "    0.01009528]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5tDy1PRfvZ0"
      },
      "source": [
        "Create datasets (as fast as possible)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tan6Ekiwfza5",
        "outputId": "dd34e90f-e265-495e-ab09-38d160a90967"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnEJakTxgJWx",
        "outputId": "22dd699a-cb66-4a57-cfeb-74c1354428ee"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeE3wo4QvOlR"
      },
      "source": [
        " Model 1: Conv1D with token embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTW5buTKvRR6"
      },
      "source": [
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOaXSsZjnKmy",
        "outputId": "29625c8c-4930-42e2-82e3-ee69194474bd"
      },
      "source": [
        "# Get summary of Conv1D model\n",
        "model_1.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gZdAVJJ3vc2"
      },
      "source": [
        "\n",
        "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
        "\n",
        "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKpHoDysgvdC",
        "outputId": "0ce4174b-2818-4b90-a757-d4cd3cc8db04"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 77s 84ms/step - loss: 0.9255 - accuracy: 0.6336 - val_loss: 0.6852 - val_accuracy: 0.7394\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 47s 83ms/step - loss: 0.6581 - accuracy: 0.7546 - val_loss: 0.6295 - val_accuracy: 0.7696\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 47s 83ms/step - loss: 0.6203 - accuracy: 0.7709 - val_loss: 0.6011 - val_accuracy: 0.7812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYvFOIBvhjpX",
        "outputId": "639b3f41-240f-4cf1-da18-dcc3e5e8c74b"
      },
      "source": [
        "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 3s 4ms/step - loss: 0.6029 - accuracy: 0.7830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6028647422790527, 0.7829670310020447]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAAtBWO2iRft",
        "outputId": "22bd0bca-31f2-4555-c91c-7fa1d8a232f8"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.2931199e-01, 1.5950313e-01, 8.2487583e-02, 3.0183598e-01,\n",
              "        2.6861310e-02],\n",
              "       [5.0202721e-01, 2.2073999e-01, 1.4192678e-02, 2.5551894e-01,\n",
              "        7.5211138e-03],\n",
              "       [1.8029025e-01, 4.9271733e-03, 2.2612307e-03, 8.1246746e-01,\n",
              "        5.3839114e-05],\n",
              "       ...,\n",
              "       [2.8276634e-06, 6.0608983e-04, 5.7351892e-04, 2.9615237e-06,\n",
              "        9.9881458e-01],\n",
              "       [5.7752185e-02, 3.6953512e-01, 1.4948265e-01, 6.7200042e-02,\n",
              "        3.5603002e-01],\n",
              "       [1.3748316e-01, 7.3944306e-01, 2.9970093e-02, 3.4588318e-02,\n",
              "        5.8515318e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydUpF6cqMll",
        "outputId": "e3769a85-ba78-41d1-be10-9ac5d51a73ab"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMfRLv0omdY4",
        "outputId": "85c9b4fa-ae3c-4584-a382-0957145272ca"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.2967032967033,\n",
              " 'f1': 0.7803481077053728,\n",
              " 'precision': 0.7794970063107775,\n",
              " 'recall': 0.782967032967033}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU1u4KlWvAQa"
      },
      "source": [
        "## Model 2: Feature extraction with pretrained token embeddings\n",
        "\n",
        "Training our own embeddings took a little while to run, slowing our experiments down.\n",
        "\n",
        "Since we're moving towards replicating the model architecture in [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it mentions they used a [pretrained GloVe embedding](https://nlp.stanford.edu/projects/glove/) as a way to initialise their token embeddings.\n",
        "\n",
        "To emulate this, let's see what results we can get with the [pretrained Universal Sentence Encoder embeddings from TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4).\n",
        "\n",
        "We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save [using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/) as an extension.\n",
        "\n",
        "The model structure will look like:\n",
        "\n",
        "```\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk8mJUNy0xOO"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOv1JQh1JdW0"
      },
      "source": [
        "Now our pretrained USE is downloaded and instantiated as a `hub.KerasLayer` instance, let's test it out on a random sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5gCkZgYJYSi",
        "outputId": "ffbde0db-edae-41f3-9628-b3849284d44b"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random training sentence:\n",
            "all @ patients with post-esd bleeding and one patient with a delayed perforation were successfully managed with conservative treatment .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.0784657  -0.04098023  0.01789245  0.04070574  0.01267017 -0.05607749\n",
            "  0.04343203 -0.01639557 -0.0224369   0.03502401  0.08823021 -0.01077881\n",
            "  0.02613548  0.07558475  0.0406533   0.00747697 -0.0898701   0.05205323\n",
            " -0.03965314  0.0732725  -0.05757886  0.0609736   0.01136613 -0.059641\n",
            "  0.0277091   0.00935705 -0.05074605  0.02424082 -0.04624016  0.02113025] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB98xmH4KO-0"
      },
      "source": [
        "The pretrained USE module from TensorFlow Hub takes care of tokenizing our text for us and outputs a 512 dimensional embedding vector.\n",
        "\n",
        "Let's put together and compile a model using our `tf_hub_embedding_layer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJue6QIthOZD"
      },
      "source": [
        "Building and fitting an NLP feature extraction model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So4lSnW_2F1i"
      },
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39r3jhefoKWG",
        "outputId": "20fdb7bb-e81f-4a10-818a-f17fb636dc04"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Exs-vDmLIs6"
      },
      "source": [
        "Checking the summary of our model we can see there's a large number of total parameters, however, the majority of these are non-trainable. This is because we set `training=False` when we instatiated our USE feature extractor layer.\n",
        "\n",
        "So when we train our model, only the top two output layers will be trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttJKg6cDihGd",
        "outputId": "f775ec5c-7a32-4c71-c4c0-2b8a2099539e"
      },
      "source": [
        "# Fit feature extractor model for 3 epochs\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 9s 13ms/step - loss: 0.9152 - accuracy: 0.6495 - val_loss: 0.7970 - val_accuracy: 0.6902\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.7702 - accuracy: 0.7011 - val_loss: 0.7566 - val_accuracy: 0.7048\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.7550 - accuracy: 0.7116 - val_loss: 0.7445 - val_accuracy: 0.7061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f71b3deb610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz8TMzLrjJYm",
        "outputId": "49581185-90ba-4651-b3f9-d9d468bed7b2"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 10s 10ms/step - loss: 0.7454 - accuracy: 0.7115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7453715801239014, 0.7115384340286255]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmLdj-1tLk3X"
      },
      "source": [
        "Since we aren't training our own custom embedding layer, training is much quicker.\n",
        "\n",
        "Let's make some predictions and evaluate our feature extraction model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oe5UxcgqvA2",
        "outputId": "fa1b554d-c51e-4659-a022-df98c751363e"
      },
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4591017 , 0.3315585 , 0.00208761, 0.19884697, 0.00840525],\n",
              "       [0.3480241 , 0.50069183, 0.0037145 , 0.14463528, 0.00293426],\n",
              "       [0.23782559, 0.17101716, 0.01569472, 0.52911067, 0.04635188],\n",
              "       ...,\n",
              "       [0.0020369 , 0.00863179, 0.05607747, 0.00101352, 0.9322403 ],\n",
              "       [0.00396787, 0.05047706, 0.18978013, 0.00139791, 0.75437707],\n",
              "       [0.2056201 , 0.2224331 , 0.50369245, 0.0066906 , 0.06156373]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8RIEnvVq7Ri",
        "outputId": "c40f0673-08c1-493a-fcea-264cb18139b9"
      },
      "source": [
        "# Convert the predictions with feature extraction model to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5yvw9brOCp",
        "outputId": "79382162-3816-49c1-c389-4e02f93ecb0c"
      },
      "source": [
        "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.15384615384616,\n",
              " 'f1': 0.7084026190451302,\n",
              " 'precision': 0.7117993675132135,\n",
              " 'recall': 0.7115384615384616}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL6wApSH0ltW"
      },
      "source": [
        "Model 3: Conv1D with character embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q-BYLq6d1me"
      },
      "source": [
        "Creating a character-level tokenizer\n",
        "\n",
        "\n",
        "Token level embeddings split sequences into tokens (words) and embeddings each of them, character embeddings split sequences into characters and creates a feature vector for each.\n",
        "\n",
        "We can create a character-level embedding by first vectorizing our sequences (after they've been split into characters) using the TextVectorization \n",
        "\n",
        "\n",
        "Before we can vectorize our sequences on a character-level we'll need to split them into characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nkoTYNvu36Bq",
        "outputId": "0561ce90-f714-49fe-e650-f3be20a347af"
      },
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a l l   @   p a t i e n t s   w i t h   p o s t - e s d   b l e e d i n g   a n d   o n e   p a t i e n t   w i t h   a   d e l a y e d   p e r f o r a t i o n   w e r e   s u c c e s s f u l l y   m a n a g e d   w i t h   c o n s e r v a t i v e   t r e a t m e n t   .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyfYyWOvx2BB"
      },
      "source": [
        "Looks like our character-splitting function works. Let's create character-level datasets by splitting our sequence datasets into characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmU_GS64S2J",
        "outputId": "756a949d-ddaf-4013-d524-dcda5c6a2246"
      },
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkLTb7FkyFPh"
      },
      "source": [
        "\n",
        "\n",
        "To figure out how long our vectorized character sequences should be, let's check the distribution of our character sequence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CjyFW5g47Ps",
        "outputId": "31063dba-8023-4380-cf82-a03ead0a6d21"
      },
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uPTgrtVJ2DSK",
        "outputId": "bb85936d-f87a-4c7e-ed72-4868cfb02e39"
      },
      "source": [
        "# Check the distribution of our sequences at character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV8yNV6l1hO4"
      },
      "source": [
        "Okay, looks like most of our sequences are between 0 and 200 characters long.\n",
        "\n",
        "Let's use NumPy's percentile to figure out what length covers 95% of our sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_k46x0Wy2n9",
        "outputId": "ad0c7ca7-085e-48f0-867e-7e04ce693953"
      },
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dDBUHMT3QwS"
      },
      "source": [
        "\n",
        "\n",
        "Now we know the sequence length which covers 95% of sequences, we'll use that in our TextVectorization layer as the output_sequence_length parameter.\n",
        "\n",
        "You can experiment here to figure out what the optimal output_sequence_length should be, perhaps using the mean results in as good results as using the 95% percentile.\n",
        "\n",
        "We'll set max_tokens (the total number of different characters in our sequences) to 28, in other words, 26 letters of the alphabet + space + OOV (out of vocabulary or unknown) tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a7uKkbP_irFg",
        "outputId": "4c039e30-11da-48ef-d13d-69388ef57499"
      },
      "source": [
        "# Get all keyboard characters for char-level embedding\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTMInkbv4Jxi"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxdh7gxv5R4i",
        "outputId": "edffe5b4-e452-43e7-84d3-beaea9250142"
      },
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFYO0vav51zl"
      },
      "source": [
        "We can also test it on random sequences of characters to make sure it's working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAcasGEh5d2O",
        "outputId": "27ab1ab6-2c2a-4f96-a8c6-d25497eb7254"
      },
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text:\n",
            "o u r   p r e l i m i n a r y   s t u d y   s u g g e s t s   ,   s u b j e c t   t o   l i m i t a t i o n s   ,   t h a t   a c u p u n c t u r e   a t   h t @   c o u l d   a f f e c t   c a r d i a c   a u t o n o m i c   n e u r a l   r e g u l a t i o n   i n   h e a l t h y   s u b j e c t s   ,   m a n i f e s t   a s   i n c r e a s e d   h r v   ,   m o s t   l i k e l y   v i a   t h e   p a r a s y m p a t h e t i c   s y s t e m   .\n",
            "\n",
            "Length of chars: 191\n",
            "\n",
            "Vectorized chars:\n",
            "[[ 7 16  8 14  8  2 12  4 15  4  6  5  8 19  9  3 16 10 19  9 16 18 18  2\n",
            "   9  3  9  9 16 22 27  2 11  3  3  7 12  4 15  4  3  5  3  4  7  6  9  3\n",
            "  13  5  3  5 11 16 14 16  6 11  3 16  8  2  5  3 13  3 11  7 16 12 10  5\n",
            "  17 17  2 11  3 11  5  8 10  4  5 11  5 16  3  7  6  7 15  4 11  6  2 16\n",
            "   8  5 12  8  2 18 16 12  5  3  4  7  6  4  6 13  2  5 12  3 13 19  9 16\n",
            "  22 27  2 11  3  9 15  5  6  4 17  2  9  3  5  9  4  6 11  8  2  5  9  2\n",
            "  10 13  8 21 15  7  9  3 12  4 23  2 12 19 21  4  5  3 13  2 14  5  8  5\n",
            "   9 19 15 14  5  3 13  2  3  4 11  9 19  9  3  2 15  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_OiBd_6j8W"
      },
      "source": [
        "You'll notice sequences with a length shorter than 290 output_seq_char_length get padded with zeros on the end, this ensures all sequences passed to our model are the same length.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8WEfkrDeNIm"
      },
      "source": [
        "Creating a character-level embedding\n",
        "We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n",
        "\n",
        "Just like our custom token embedding, we can do so using the tensorflow.keras.layers.Embedding class.\n",
        "\n",
        "Our character-level embedding layer requires an input dimension and output dimension. \n",
        "\n",
        "The input dimension nput_dim will be equal to the number of different characters in our char_vocab (28). And since we're following the structure of the model in Figure 1 of Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstractsthe output dimension of the character embedding output_dim will be 25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQHt1hSy57cu",
        "outputId": "94bea74c-38a6-475e-dd7d-4df39397ba42"
      },
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=True,\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "o u r   p r e l i m i n a r y   s t u d y   s u g g e s t s   ,   s u b j e c t   t o   l i m i t a t i o n s   ,   t h a t   a c u p u n c t u r e   a t   h t @   c o u l d   a f f e c t   c a r d i a c   a u t o n o m i c   n e u r a l   r e g u l a t i o n   i n   h e a l t h y   s u b j e c t s   ,   m a n i f e s t   a s   i n c r e a s e d   h r v   ,   m o s t   l i k e l y   v i a   t h e   p a r a s y m p a t h e t i c   s y s t e m   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[ 0.04878641  0.04962002  0.01991138 ... -0.04528921 -0.00329228\n",
            "   -0.0164424 ]\n",
            "  [ 0.0446203   0.0425423  -0.02520189 ...  0.04162499  0.04742401\n",
            "   -0.00740603]\n",
            "  [ 0.00080427  0.0035476  -0.01511031 ...  0.01834874  0.02659161\n",
            "    0.00612857]\n",
            "  ...\n",
            "  [-0.0019945   0.04662419 -0.00142326 ...  0.0266779   0.02975614\n",
            "   -0.00783849]\n",
            "  [-0.0019945   0.04662419 -0.00142326 ...  0.0266779   0.02975614\n",
            "   -0.00783849]\n",
            "  [-0.0019945   0.04662419 -0.00142326 ...  0.0266779   0.02975614\n",
            "   -0.00783849]]]\n",
            "\n",
            "Character embedding shape: (1, 290, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bzv_FmFd9bN"
      },
      "source": [
        "Building a Conv1D model to fit on character embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVwC0xadtb5r"
      },
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1D_char_embedding\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwdxy2gQu7Wm",
        "outputId": "fb8f0ba3-5cc5-49c8-f7b1-1a04fe195cad"
      },
      "source": [
        "# Check the summary of conv1d_char_model\n",
        "model_3.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_conv1D_char_embedding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "char_vectorizer (TextVectori (None, 290)               0         \n",
            "_________________________________________________________________\n",
            "char_embed (Embedding)       (None, 290, 25)           1750      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 290, 64)           8064      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 10,139\n",
            "Trainable params: 10,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixTsGYBbnXn9",
        "outputId": "5d3e4fe5-5ee3-4e6b-e7ed-4068eccb0a67"
      },
      "source": [
        "# Create char datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qpv1NR_cC1h"
      },
      "source": [
        "Just like our token-level sequence model, to save time with our experiments, we'll fit the character-level model on 10% of batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGokmMdGn91w",
        "outputId": "83376bb5-68ea-429e-f2b8-ef1d9e5b6f46"
      },
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 5s 7ms/step - loss: 1.2940 - accuracy: 0.4783 - val_loss: 1.1054 - val_accuracy: 0.5688\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 1.0354 - accuracy: 0.5903 - val_loss: 0.9788 - val_accuracy: 0.6114\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 4s 7ms/step - loss: 0.9450 - accuracy: 0.6267 - val_loss: 0.8960 - val_accuracy: 0.6569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHO-fl9oA5V",
        "outputId": "085a9b75-37b3-40ca-e617-89600c148b51"
      },
      "source": [
        "# Evaluate model_3 on whole validation char dataset\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.9049 - accuracy: 0.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9048993587493896, 0.6522243022918701]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0u4QzT2xMgF",
        "outputId": "1ad833c4-9f60-4e53-fd66-a16908b4b424"
      },
      "source": [
        "# Make predictions with character model only\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16027446, 0.48349142, 0.08786038, 0.2083707 , 0.06000303],\n",
              "       [0.236796  , 0.4683586 , 0.02932157, 0.18887475, 0.07664907],\n",
              "       [0.08209941, 0.27919096, 0.23854834, 0.2690622 , 0.13109908],\n",
              "       ...,\n",
              "       [0.0239641 , 0.01711017, 0.08318114, 0.02448583, 0.8512588 ],\n",
              "       [0.02126833, 0.06472842, 0.47538698, 0.02678069, 0.4118356 ],\n",
              "       [0.38300672, 0.38233113, 0.14024216, 0.07757578, 0.01684421]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdPUXiZux68-",
        "outputId": "174b2c5a-3b27-4c01-f551-09d21e902082"
      },
      "source": [
        "# Convert predictions to classes\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 1, ..., 4, 2, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NCDZD7cyoj7",
        "outputId": "d0c3ebc0-98e9-43d2-ffe9-5f8ceacf5941"
      },
      "source": [
        "# Calculate Conv1D char only model results\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 65.2224281742354,\n",
              " 'f1': 0.6402271077964911,\n",
              " 'precision': 0.6400828263749139,\n",
              " 'recall': 0.652224281742354}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1krE-3csz3N-"
      },
      "source": [
        "Combining pretrained token embeddings + character embeddings (hybrid embedding layer)\n",
        "\n",
        "Alright, now things are going to get spicy.\n",
        "\n",
        "In moving closer to build a model similar to the one in Figure 1 of Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts it's time we tackled the hybrid token embedding layer they speak of.\n",
        "\n",
        "This hybrid token embedding layer is a combination of token embeddings and character embeddings. In other words, they create a stacked embedding to represent sequences before passing them to the sequence label prediction layer.\n",
        "\n",
        "So far we've built two models which have used token and character-level embeddings, however, these two models have used each of these embeddings exclusively.\n",
        "\n",
        "To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n",
        "1. Create a token-level model (similar to `model_1`)\n",
        "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
        "3. Combine using layers.Concatenate, the outputs of 1 and 2\n",
        "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4 Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*\n",
        "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DI2KQf7z-yo"
      },
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21PRnEmK2a0Y",
        "outputId": "6c659ca7-cacb-4aff-eeeb-87a935a2d2f8"
      },
      "source": [
        "# Get summary of token and character model\n",
        "model_4.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_token_and_char_embeddings\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_input (InputLayer)        [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_vectorizer (TextVectorizat (None, 290)          0           char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          65664       universal_sentence_encoder[1][0] \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 50)           10200       char_embed[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_char_hybrid (Concatenate) (None, 178)          0           dense_4[0][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 178)          0           token_char_hybrid[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 200)          35800       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 5)            1005        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 256,912,243\n",
            "Trainable params: 114,419\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yx8PFSc2hqE"
      },
      "source": [
        "# Compile token char model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-bD7bL-UIn3"
      },
      "source": [
        "And again, to keep our experiments fast, we'll fit our token-character-hybrid model on 10% of training and validate on 10% of validation batches. However, the difference with this model is that it requires two inputs, token-level sequences and character-level sequences.\n",
        "\n",
        " create a tf.data.Dataset with a tuple as it's first input, for example ((token_data, char_data), (label))`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYU0fX6rpbgI"
      },
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlOs99Emp52r",
        "outputId": "546b65e6-42bf-411b-f852-d83ac8a0429d"
      },
      "source": [
        "# Check out training char and token embedding dataset\n",
        "train_char_token_dataset, val_char_token_dataset"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANLBMpRlfA73"
      },
      "source": [
        "Fitting a model on token and character-level sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0c25coprwp",
        "outputId": "598f510e-1e9a-4308-c053-f8a8b6c49a06"
      },
      "source": [
        "# Fit the model on tokens and chars\n",
        "model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of token and characters\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 28s 50ms/step - loss: 0.7403 - accuracy: 0.7184 - val_loss: 0.6635 - val_accuracy: 0.7507\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 27s 48ms/step - loss: 0.7055 - accuracy: 0.7317 - val_loss: 0.6463 - val_accuracy: 0.7566\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 26s 46ms/step - loss: 0.7044 - accuracy: 0.7310 - val_loss: 0.6392 - val_accuracy: 0.7550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfAMuoJett_t",
        "outputId": "e933556e-b760-4ae9-ab39-4704bcfbff2c"
      },
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 20s 22ms/step - loss: 0.6459 - accuracy: 0.7532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6459140777587891, 0.7532106637954712]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSimi5vYY2xF"
      },
      "source": [
        " Our token-character hybrid model has come to life!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z_zbrXTYN7G",
        "outputId": "db41f68f-0571-480c-d90c-ebd80b2290ad"
      },
      "source": [
        "# Make predictions using the token-character model hybrid\n",
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.69196469e-01, 2.61619449e-01, 1.61003985e-03, 2.65044928e-01,\n",
              "        2.52910540e-03],\n",
              "       [3.81642878e-01, 4.45949733e-01, 2.30655656e-03, 1.69219151e-01,\n",
              "        8.81658925e-04],\n",
              "       [3.44508201e-01, 7.74589851e-02, 4.52146046e-02, 5.07374406e-01,\n",
              "        2.54438184e-02],\n",
              "       ...,\n",
              "       [2.89483054e-04, 2.87431013e-03, 4.13980186e-02, 1.64898418e-04,\n",
              "        9.55273271e-01],\n",
              "       [1.23143196e-02, 1.07773066e-01, 1.53898403e-01, 5.09712659e-03,\n",
              "        7.20917046e-01],\n",
              "       [1.80316538e-01, 6.80185199e-01, 1.06860526e-01, 1.12730926e-02,\n",
              "        2.13646162e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic5MCrFxYgsB",
        "outputId": "336648d2-b01f-410e-b9e0-bc81d17215fb"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "model_4_preds"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBNPIRIC7EsE",
        "outputId": "ab78f355-4cc4-499f-e506-d98c42377675"
      },
      "source": [
        "# Get results of token-char-hybrid model\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.32106447769098,\n",
              " 'f1': 0.7501579002330037,\n",
              " 'precision': 0.7517899309288941,\n",
              " 'recall': 0.7532106447769098}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5ctbxCih6Z"
      },
      "source": [
        "Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings \n",
        "\n",
        "we took our own knowledge about the data and encoded it in a numerical way to give our model more information about our samples?\n",
        "\n",
        "The process of applying your own knowledge to build features as input to a model is called **feature engineering**.\n",
        "\n",
        "Can you think of something important about the sequences we're trying to classify?\n",
        "\n",
        "If you were to look at an abstract, would you expect the sentences to appear in order? Or does it make sense if they were to appear sequentially? For example, sequences labelled CONCLUSIONS at the beggining and sequences labelled OBJECTIVE at the end?\n",
        "\n",
        "Abstracts typically come in a sequential order, such as:\n",
        ". OBJECTIVE\n",
        "\n",
        ". METHODS\n",
        "\n",
        ". METHODS\n",
        "\n",
        ". METHODS\n",
        "\n",
        ". RESULTS\n",
        "\n",
        ". CONCLUSIONS\n",
        "\n",
        "Or\n",
        "\n",
        ". BACKGROUND \n",
        ". OBJECTIVE` \n",
        ". METHODS\n",
        ". METHODS\n",
        ". RESULTS\n",
        ". RESULTS\n",
        ". CONCLUSIONS\n",
        ". CONCLUSIONS\n",
        "\n",
        "Of course, we can't engineer the sequence labels themselves into the training data (we don't have these at test time), but we can encode the order of a set of sequences in an abstract.\n",
        "\n",
        "For example,\n",
        ". Sentence 1 of 10\n",
        "\n",
        ". Sentence 2 of 10\n",
        "\n",
        ". Sentence 3 of 10\n",
        "\n",
        ". Sentence 4 of 10\n",
        "\n",
        "\n",
        "\n",
        "You might've noticed this when we created our preprocess_text_with_line_numbers()` function. When we read in a text file of abstracts, we counted the number of lines in an abstract as well as the number of each line itself.\n",
        "\n",
        "Doing this led to the line_number and total_lines columns of our DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Htf-tnFcEcAn",
        "outputId": "440cfca1-9d57-4a5a-a4c3-90eb82c786ba"
      },
      "source": [
        "# Inspect training dataframe\n",
        "train_df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      target  ... total_lines\n",
              "0  OBJECTIVE  ...          11\n",
              "1    METHODS  ...          11\n",
              "2    METHODS  ...          11\n",
              "3    METHODS  ...          11\n",
              "4    METHODS  ...          11\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJVhuU7cMd0-",
        "outputId": "c3cf14ed-aa69-4f2a-fe63-a2192e3cc807"
      },
      "source": [
        "# How many different line numbers are there?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     15000\n",
              "1     15000\n",
              "2     15000\n",
              "3     15000\n",
              "4     14992\n",
              "5     14949\n",
              "6     14758\n",
              "7     14279\n",
              "8     13346\n",
              "9     11981\n",
              "10    10041\n",
              "11     7892\n",
              "12     5853\n",
              "13     4152\n",
              "14     2835\n",
              "15     1861\n",
              "16     1188\n",
              "17      751\n",
              "18      462\n",
              "19      286\n",
              "20      162\n",
              "21      101\n",
              "22       66\n",
              "23       33\n",
              "24       22\n",
              "25       14\n",
              "26        7\n",
              "27        4\n",
              "28        3\n",
              "29        1\n",
              "30        1\n",
              "Name: line_number, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rKoNMSBNImLG",
        "outputId": "731ba071-4fff-4999-ff3a-4acad44f0d0d"
      },
      "source": [
        "# Check the distribution of \"line_number\" column\n",
        "train_df.line_number.plot.hist()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f71581cc110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPnEkJvXKuf9"
      },
      "source": [
        "Looking at the distribution of the line_number column, it looks like the majority of lines have a position of 15 or less.\n",
        "\n",
        "Knowing this, let's set the depth parameter of tf.one_hot to 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjdKcXUMkgE"
      },
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column \n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7BERNOQK723",
        "outputId": "df60fca0-d5b9-4acc-e48d-04547c08c38f"
      },
      "source": [
        "# Check one-hot encoded \"line_number\" feature samples\n",
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 15]), <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxYgKu6tMBbg"
      },
      "source": [
        "We can do the same as we've done for our `\"line_number\"` column witht he `\"total_lines\"` column. First, let's find an appropriate value for the `depth` parameter of `tf.one_hot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3bLbdWzOBmY",
        "outputId": "3620f67b-37c7-4292-9407-81a37d0235d1"
      },
      "source": [
        "# How many different numbers of lines are there?\n",
        "train_df[\"total_lines\"].value_counts()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: total_lines, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "oxDN9ASLL9uY",
        "outputId": "fe0c25dd-a131-46b0-a10b-574fc591a76b"
      },
      "source": [
        "# Check the distribution of total lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBWX2cIHN_1J"
      },
      "source": [
        "Looking at the distribution of our `\"total_lines\"` column, a value of 20 looks like it covers the majority of samples.\n",
        "\n",
        "We can confirm this with [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or736pZLNwWn",
        "outputId": "af6ff8a6-8d0a-42ff-e538-e8c80dcc8147"
      },
      "source": [
        "# Check the coverage of a \"total_lines\" value of 20\n",
        "np.percentile(train_df.total_lines, 98) # a value of 20 covers 98% of samples"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy8Ds74HOLXQ"
      },
      "source": [
        "Let's one-hot-encode our `\"total_lines\"` column just as we did our `\"line_number\"` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egqq3LnnN0Z6",
        "outputId": "d9718f27-1a68-44f4-fae5-d82da65eb3b1"
      },
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column \n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Check shape and samples of total lines one-hot tensor\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 20]), <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVJWCANtQMiJ"
      },
      "source": [
        "Building a tribrid embedding model\n",
        "\n",
        "Woohoo! Positional embedding tensors ready.\n",
        "\n",
        "It's time to build the biggest model we've built yet. One which incorporates token embeddings, character embeddings and our newly crafted positional embeddings.\n",
        "\n",
        "We'll be venturing into uncovered territory but there will be nothing here you haven't practiced before.\n",
        "\n",
        "More specifically we're going to go through the following steps:\n",
        "\n",
        "1. Create a token-level model (similar to `model_1`)\n",
        "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
        "3. Create a `\"line_number\"` model (takes in one-hot-encoded `\"line_number\"` tensor and passes it through a non-linear layer)\n",
        "4. Create a `\"total_lines\"` model (takes in one-hot-encoded `\"total_lines\"` tensor and passes it through a non-linear layer)\n",
        "5. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2 into a token-character-hybrid embedding and pass it series of output to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "6. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 3, 4 and 5 into a token-character-positional tribrid embedding \n",
        "7. Create an output layer to accept the tribrid embedding and output predicted label probabilities\n",
        "8. Combine the inputs of 1, 2, 3, 4 and outputs of 7 into a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
        "\n",
        "Woah! That's alot... but nothing we're not capable of. Let's code it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPiFnY8E0oPS"
      },
      "source": [
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_embeddings)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input, \n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVhTeiveWf4X"
      },
      "source": [
        "There's a lot going on here... let's visualize what's happening with a summary by plotting our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7eJOhlKfVQJ",
        "outputId": "3efb2a2d-7e40-4d40-8021-c179b6ece627"
      },
      "source": [
        "# Get a summary of our token, char and positional embedding model\n",
        "model_5.summary()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_inputs (InputLayer)        [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_vectorizer (TextVectorizat (None, 290)          0           char_inputs[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "token_inputs (InputLayer)       [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[3][0]            \n",
            "__________________________________________________________________________________________________\n",
            "universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 64)           14848       char_embed[3][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_char_hybrid_embedding (Co (None, 576)          0           universal_sentence_encoder[3][0] \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "line_number_input (InputLayer)  [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "total_lines_input (InputLayer)  [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 256)          147712      token_char_hybrid_embedding[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 32)           512         line_number_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 32)           672         total_lines_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 256)          0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "token_char_positional_embedding (None, 320)          0           dense_11[0][0]                   \n",
            "                                                                 dense_12[0][0]                   \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output_layer (Dense)            (None, 5)            1605        token_char_positional_embedding[0\n",
            "==================================================================================================\n",
            "Total params: 256,964,923\n",
            "Trainable params: 167,099\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud8arQOTUtRl",
        "outputId": "68810437-0b07-4470-b178-d371f9cc2b4c"
      },
      "source": [
        "# Check which layers of our model are trainable or not\n",
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f715796af90> True\n",
            "<tensorflow.python.keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x7f71adc6e310> True\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7157976c50> True\n",
            "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f71adc2eb90> True\n",
            "<tensorflow_hub.keras_layer.KerasLayer object at 0x7f726a74d7d0> False\n",
            "<tensorflow.python.keras.layers.wrappers.Bidirectional object at 0x7f71578116d0> True\n",
            "<tensorflow.python.keras.layers.merge.Concatenate object at 0x7f716b30ad50> True\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f715786ef90> True\n",
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7157366f10> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f7157299c50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f716b288450> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f71574f7f10> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f7157366d10> True\n",
            "<tensorflow.python.keras.layers.merge.Concatenate object at 0x7f716b6c0e50> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f71572b7850> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUCaJPKY9o_"
      },
      "source": [
        "Now our model is constructed, let's compile it.\n",
        "\n",
        "This time, we're going to introduce a new parameter to our loss function called `label_smoothing`. Label smoothing helps to regularize our model (prevent overfitting) by making sure it doesn't get too focused on applying one particular label to a sample.\n",
        "\n",
        "For example, instead of having an output prediction of: \n",
        "* `[0.0, 0.0, 1.0, 0.0, 0.0]` for a sample (the model is very confident the right label is index 2).\n",
        "\n",
        "It's predictions will get smoothed to be something like:\n",
        "* `[0.01, 0.01, 0.096, 0.01, 0.01]` giving a small activation to each of the other labels, in turn, hopefully improving generalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwYd_dWPS8EB"
      },
      "source": [
        "# Compile token, char, positional embedding model\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrXEGlcUZXAE"
      },
      "source": [
        "### Create tribrid embedding datasets and fit tribrid model\n",
        "\n",
        "Model compiled!\n",
        "\n",
        "Again, to keep our experiments swift, let's fit on 20,000 examples for 3 epochs.\n",
        "\n",
        "This time our model requires four feature inputs:\n",
        "1. Train line numbers one-hot tensor (`train_line_numbers_one_hot`)\n",
        "2. Train total lines one-hot tensor (`train_total_lines_one_hot`)\n",
        "3. Token-level sequences tensor (`train_sentences`)\n",
        "4. Char-level sequences tensor (`train_chars`)\n",
        "\n",
        "We can pass these as tuples to our `tf.data.Dataset.from_tensor_slices()` method to create appropriately shaped and batched `PrefetchedDataset`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FDNHSIRyEE2",
        "outputId": "f725677c-9727-4116-d913-3a2098b873ae"
      },
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
        "                                                                train_total_lines_one_hot, # total lines\n",
        "                                                                train_sentences, # train tokens\n",
        "                                                                train_chars)) # train chars\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiAjolB7yLxw",
        "outputId": "23360562-67d7-4078-dc58-4177e9b90a26"
      },
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 36s 52ms/step - loss: 1.0963 - accuracy: 0.7294 - val_loss: 0.9847 - val_accuracy: 0.8078\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 29s 51ms/step - loss: 0.9768 - accuracy: 0.8089 - val_loss: 0.9603 - val_accuracy: 0.8195\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 25s 45ms/step - loss: 0.9605 - accuracy: 0.8177 - val_loss: 0.9508 - val_accuracy: 0.8248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS88IaN_auu8"
      },
      "source": [
        "Tribrid model trained! Time to make some predictions with it and evaluate them just as we've done before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6AtA9ffcC8Y",
        "outputId": "62443c4b-3a85-4fdf-c842-0b888af46e80"
      },
      "source": [
        "# Make predictions with token-char-positional hybrid model\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 20s 19ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.503937  , 0.12390389, 0.0106807 , 0.3361257 , 0.02535271],\n",
              "       [0.5125982 , 0.11256028, 0.03972213, 0.32154512, 0.01357422],\n",
              "       [0.2644689 , 0.13617654, 0.14073932, 0.37289593, 0.08571932],\n",
              "       ...,\n",
              "       [0.04319686, 0.11381648, 0.04619621, 0.03261479, 0.76417565],\n",
              "       [0.03194898, 0.34930837, 0.08909828, 0.02664166, 0.5030027 ],\n",
              "       [0.15472952, 0.5490431 , 0.16382506, 0.0378148 , 0.09458752]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7x2LKrFc6CN",
        "outputId": "783eb374-bc2a-430c-90db-58a3d9fd07cb"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dogdVk02dO62",
        "outputId": "a3dcf646-9334-44be-e1e9-aa2e6ae63072"
      },
      "source": [
        "# Calculate results of token-char-positional hybrid model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.71878723685953,\n",
              " 'f1': 0.8260035299876177,\n",
              " 'precision': 0.8254464675510393,\n",
              " 'recall': 0.8271878723685953}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yranVE5soBdf"
      },
      "source": [
        "Compare model results \n",
        "\n",
        "Far out, we've come a long way. From a baseline model to training a model containing three different kinds of embeddings.\n",
        "\n",
        "Now it's time to compare each model's performance against each other.\n",
        "\n",
        "We'll also be able to compare our model's to the PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts\n",
        "\n",
        "Since all of our model results are in dictionaries, let's combine them into a pandas DataFrame to visualize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "uJtoRSYGb2VP",
        "outputId": "83aa4425-d596-4910-98b2-7bf6d586e83b"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
        "                                  \"pretrained_token_embed\": model_2_results,\n",
        "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
        "                                  \"hybrid_char_token_embed\": model_4_results,\n",
        "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>72.183238</td>\n",
              "      <td>0.718647</td>\n",
              "      <td>0.721832</td>\n",
              "      <td>0.698925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>custom_token_embed_conv1d</th>\n",
              "      <td>78.296703</td>\n",
              "      <td>0.779497</td>\n",
              "      <td>0.782967</td>\n",
              "      <td>0.780348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pretrained_token_embed</th>\n",
              "      <td>71.153846</td>\n",
              "      <td>0.711799</td>\n",
              "      <td>0.711538</td>\n",
              "      <td>0.708403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>custom_char_embed_conv1d</th>\n",
              "      <td>65.222428</td>\n",
              "      <td>0.640083</td>\n",
              "      <td>0.652224</td>\n",
              "      <td>0.640227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hybrid_char_token_embed</th>\n",
              "      <td>75.321064</td>\n",
              "      <td>0.751790</td>\n",
              "      <td>0.753211</td>\n",
              "      <td>0.750158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tribrid_pos_char_token_embed</th>\n",
              "      <td>82.718787</td>\n",
              "      <td>0.825446</td>\n",
              "      <td>0.827188</td>\n",
              "      <td>0.826004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               accuracy  precision    recall        f1\n",
              "baseline                      72.183238   0.718647  0.721832  0.698925\n",
              "custom_token_embed_conv1d     78.296703   0.779497  0.782967  0.780348\n",
              "pretrained_token_embed        71.153846   0.711799  0.711538  0.708403\n",
              "custom_char_embed_conv1d      65.222428   0.640083  0.652224  0.640227\n",
              "hybrid_char_token_embed       75.321064   0.751790  0.753211  0.750158\n",
              "tribrid_pos_char_token_embed  82.718787   0.825446  0.827188  0.826004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G--0tQkb5tq"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "JHtN7qJ3cAA3",
        "outputId": "6e4d5d1a-c223-4092-c6a9-6034b1c5b98e"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "PtDMFKsCcD1j",
        "outputId": "331892bf-0494-4e65-d046-3fce6831bf27"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEoLsCNbwNRA"
      },
      "source": [
        "Based on F1-scores, it looks like our tribrid embedding model performs the best by a fair margin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk5rMP0rarWG"
      },
      "source": [
        "Save and load best performing model\n",
        "\n",
        "Since we've been through a fair few experiments, it's a good idea to save our best performing model so we can reuse it without having to retrain it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRalPoXEi0Es",
        "outputId": "0ba7bb45-c58e-482c-c45c-81cb706e7979"
      },
      "source": [
        "# Save best performing model to SavedModel format (default)\n",
        "model_5.save(\"skimlit_tribrid_model\") # model will be saved to path specified by string"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: skimlit_tribrid_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: skimlit_tribrid_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMzS3dWPx9xu"
      },
      "source": [
        "Optional: If you're using Google Colab, you might want to copy your saved model to Google Drive (or [download it](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh)) for more permanent storage (Google Colab files disappear after you disconnect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgsma17oUtAE"
      },
      "source": [
        "# Example of copying saved model from Google Colab to Drive (requires Google Drive to be mounted)\n",
        "# !cp skim_lit_best_model -r /content/drive/MyDrive/tensorflow_course/skim_lit"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Go3DCssvA1o"
      },
      "source": [
        "\n",
        "Like all good cooking shows, we've got a pretrained model (exactly the same kind of model we built for model_5\n",
        "\n",
        "So to make sure we're all using the same model for evaluation, we'll download it and load it in. \n",
        "\n",
        "And when loading in our model, since it uses a couple of custom objects (our TensorFlow Hub layer and TextVectorization layer), we'll have to load it in by specifying them in the custom_objects parameter of tf.keras.models.load_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dQESoCSuUnK",
        "outputId": "6ebb6187-9491-4d72-950a-2bb5b5d69b2a"
      },
      "source": [
        "# Download pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
        "!mkdir skimlit_gs_model\n",
        "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 14:31:03--  https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 74.125.132.128, 74.125.201.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 962957902 (918M) [application/zip]\n",
            "Saving to: skimlit_tribrid_model.zip\n",
            "\n",
            "skimlit_tribrid_mod 100%[===================>] 918.35M  40.9MB/s    in 13s     \n",
            "\n",
            "2021-07-20 14:31:16 (72.7 MB/s) - skimlit_tribrid_model.zip saved [962957902/962957902]\n",
            "\n",
            "Archive:  skimlit_tribrid_model.zip\n",
            "   creating: skimlit_gs_model/skimlit_tribrid_model/\n",
            "   creating: skimlit_gs_model/skimlit_tribrid_model/assets/\n",
            "   creating: skimlit_gs_model/skimlit_tribrid_model/variables/\n",
            "  inflating: skimlit_gs_model/skimlit_tribrid_model/variables/variables.index  \n",
            "  inflating: skimlit_gs_model/skimlit_tribrid_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: skimlit_gs_model/skimlit_tribrid_model/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDRneseeZSRY",
        "outputId": "d9da53f9-43f4-4e8c-ad93-a5556e6657d2"
      },
      "source": [
        "# Import TensorFlow model dependencies (if needed) - https://github.com/tensorflow/tensorflow/issues/38250 \n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "model_path = \"skimlit_gs_model/skimlit_tribrid_model\"\n",
        "\n",
        "# Load downloaded model from Google Storage\n",
        "loaded_model = tf.keras.models.load_model(model_path,\n",
        "                                          custom_objects={\"TextVectorization\": TextVectorization, # required for char vectorization\n",
        "                                                          \"KerasLayer\": hub.KerasLayer}) # required for token embedding"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOY7As4Dxdn_"
      },
      "source": [
        "### Make predictions and evalaute them against the truth labels\n",
        "\n",
        "To make sure our model saved and loaded correctly, let's make predictions with it, evaluate them and then compare them to the prediction results we calculated earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmLdyobSv95I",
        "outputId": "2e31c5e2-a700-4518-bfa7-f13ee86ce668"
      },
      "source": [
        "# Make predictions with the loaded model on the validation set\n",
        "loaded_pred_probs = loaded_model.predict(val_pos_char_token_dataset, verbose=1)\n",
        "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
        "loaded_preds[:10]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 22s 21ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 4, 4, 4, 4, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS4XMK6yxEn0",
        "outputId": "721e8119-f99a-487f-f7aa-2c78a3b14075"
      },
      "source": [
        "# Evaluate loaded model's predictions\n",
        "loaded_model_results = calculate_results(val_labels_encoded,\n",
        "                                         loaded_preds)\n",
        "loaded_model_results"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.83132530120481,\n",
              " 'f1': 0.8272937671199255,\n",
              " 'precision': 0.8268115620164092,\n",
              " 'recall': 0.8283132530120482}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_zJXe1v1Evs"
      },
      "source": [
        "Now let's compare our loaded model's predictions with the prediction results we obtained before saving our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNDhkLYzznXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "6e55501f-13e6-4f76-93ac-fd049a5d7957"
      },
      "source": [
        "# Compare loaded model results with original trained model results (should return no errors)\n",
        "assert model_5_results == loaded_model_results"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-7f3788e50768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare loaded model results with original trained model results (should return no errors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mmodel_5_results\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mloaded_model_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5EMfCId1WKr"
      },
      "source": [
        "It's worth noting that loading in a SavedModel unfreezes all layers (makes them all trainable). So if you want to freeze any layers, you'll have to set their trainable attribute to `False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZEk80xiqNLT",
        "outputId": "8844fe80-60ab-45a3-ee76-b28541032165"
      },
      "source": [
        "# Check loaded model summary (note the number of trainable parameters)\n",
        "loaded_model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_inputs (InputLayer)        [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_vectorizer (TextVectorizat (None, 290)          0           char_inputs[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "token_inputs (InputLayer)       [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 64)           14848       char_embed[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_char_hybrid_embedding (Co (None, 576)          0           universal_sentence_encoder[0][0] \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "line_number_input (InputLayer)  [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "total_lines_input (InputLayer)  [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 256)          147712      token_char_hybrid_embedding[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 32)           512         line_number_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 32)           672         total_lines_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 256)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "token_char_positional_embedding (None, 320)          0           dense_16[0][0]                   \n",
            "                                                                 dense_17[0][0]                   \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output_layer (Dense)            (None, 5)            1605        token_char_positional_embedding[0\n",
            "==================================================================================================\n",
            "Total params: 256,964,923\n",
            "Trainable params: 167,099\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uq0MFPiaoUb"
      },
      "source": [
        "Evaluate model on test dataset\n",
        "\n",
        "To make our model's performance more comparable with the results reported in Table 3 of the [*PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts paper, let's make predictions on the test dataset and evaluate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkFb3giT2FYW",
        "outputId": "ce0975aa-8dd3-458a-ca71-574ea30cacb2"
      },
      "source": [
        "# Create test dataset batch and prefetched\n",
        "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
        "                                                               test_total_lines_one_hot,\n",
        "                                                               test_sentences,\n",
        "                                                               test_chars))\n",
        "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
        "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Check shapes\n",
        "test_pos_char_token_dataset"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpoQj-PexFf9",
        "outputId": "bcbf6609-5d17-45fd-d28e-d6a285b29dc1"
      },
      "source": [
        "# Make predictions on the test dataset\n",
        "test_pred_probs = loaded_model.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "942/942 [==============================] - 20s 21ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([3, 3, 2, 2, 4, 4, 4, 1, 4, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avvjksEqxe_0",
        "outputId": "23318712-6f74-4a53-f496-733c05742152"
      },
      "source": [
        "# Evaluate loaded model test predictions\n",
        "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds)\n",
        "loaded_model_test_results"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.3859299817488,\n",
              " 'f1': 0.8228365555962726,\n",
              " 'precision': 0.8224125471470242,\n",
              " 'recall': 0.823859299817488}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eupgOniJ3rLr"
      },
      "source": [
        "It seems our best model (so far) still has some ways to go to match the performance of the results in the paper (their model gets 90.0 F1-score on the test dataset, where as ours gets ~82.1 F1-score).\n",
        "\n",
        "However, as we discussed before our model has only been trained on 20,000 out of the total ~180,000 sequences in the RCT 20k dataset. We also haven't fine-tuned our pretrained embeddings (the paper fine-tunes GloVe embeddings). So there's a couple of extensions we could try to improve our results."
      ]
    }
  ]
}